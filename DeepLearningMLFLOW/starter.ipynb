{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\nico_\\Desktop\\MLOPS\\data\\winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3 ,  0.25,  0.22, ...,  0.5 , 10.5 ,  6.  ],\n",
       "       [ 7.8 ,  0.3 ,  0.29, ...,  0.38,  9.  ,  6.  ],\n",
       "       [ 7.4 ,  0.38,  0.27, ...,  0.43, 10.  ,  5.  ],\n",
       "       ...,\n",
       "       [ 7.6 ,  0.27,  0.52, ...,  0.53, 11.4 ,  6.  ],\n",
       "       [ 6.3 ,  0.24,  0.29, ...,  0.38, 10.6 ,  6.  ],\n",
       "       [ 8.1 ,  0.27,  0.35, ...,  0.63, 10.4 ,  8.  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['quality'], axis=1).values\n",
    "y_train = train['quality'].values\n",
    "\n",
    "# Test dataset\n",
    "X_test = test.drop(['quality'], axis=1).values\n",
    "y_test = test['quality'].values\n",
    "\n",
    "# Splitting the train data into train and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "signature = infer_signature(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.86621852e+00, 2.80377808e-01, 3.32597005e-01, 6.42164738e+00,\n",
       "       4.55513955e-02, 3.53556841e+01, 1.38792376e+02, 9.94074221e-01,\n",
       "       3.18919333e+00, 4.88396869e-01, 1.05005673e+01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "def train_model(params, epochs, X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "\n",
    "    # Define model architecture\n",
    "    mean=np.mean(X_train, axis=0)\n",
    "    var = np.var(X_train, axis=0)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.Input([X_train.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(learning_rate=params['lr'], momentum=params['momentum']),\n",
    "    loss='mean_squared_error', \n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=epochs, batch_size=64)\n",
    "    \n",
    "        # Evaluate the model\n",
    "        eval_result = model.evaluate(X_valid, y_valid, batch_size=64)\n",
    "\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        # Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric('eval_rmse', eval_rmse)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.tensorflow.log_model(model, 'model', signature=signature)\n",
    "\n",
    "        return {'loss': eval_rmse, 'status' : STATUS_OK, 'model' : model}\n",
    "\n",
    "\n",
    "# On crée une \"sous-expérience\" (nested run) à l'intérieur d'une expérience principale\n",
    "# Ensuite, la grande expérience principale (mlflow.start_run()) regroupe toutes les sous-expériences.\n",
    "# Cela permet d’organiser proprement les logs et d’analyser facilement chaque test.\n",
    "# Sans nested=True, chaque exécution écraserait la précédente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLFlow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        X_train=X_train,\n",
    "        y_train =y_train,\n",
    "        X_valid=X_valid,\n",
    "        y_valid=y_valid,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# Cette fonction est utilisée par Hyperopt pour tester différents hyperparamètres et sélectionner les meilleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    'lr':hp.loguniform('lr',np.log(1e-5),np.log(1e-1)),\n",
    "    'momentum':hp.uniform('momentum',0.0,1.0)\n",
    "}\n",
    "\n",
    "# On utilise log pour avoir des valeurs très petite dans l'intervale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params contient quelque chose comme :\n",
    "params = {\n",
    "    'lr': 0.00123,  # Une valeur choisie par Hyperopt\n",
    "    'momentum': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 433ms/step - loss: 35.9184 - root_mean_squared_error: 5.9932\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 32.5909 - root_mean_squared_error: 5.7077 - val_loss: 27.7882 - val_root_mean_squared_error: 5.2715\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 28.3634 - root_mean_squared_error: 5.3257\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4240 - root_mean_squared_error: 5.1399 - val_loss: 22.6039 - val_root_mean_squared_error: 4.7544\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 21.3557 - root_mean_squared_error: 4.6212\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2869 - root_mean_squared_error: 4.6134 - val_loss: 18.3185 - val_root_mean_squared_error: 4.2800\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 18.7071 - root_mean_squared_error: 4.3252\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1327 - root_mean_squared_error: 4.2581 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 350ms/step - loss: 35.4157 - root_mean_squared_error: 5.9511\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18.7002 - root_mean_squared_error: 4.2530   \n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 18.5216 - root_mean_squared_error: 4.2308 - val_loss: 2.5994 - val_root_mean_squared_error: 1.6123\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.6545 - root_mean_squared_error: 1.2863\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0966 - root_mean_squared_error: 1.4476 - val_loss: 1.8423 - val_root_mean_squared_error: 1.3573\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 1.5583 - root_mean_squared_error: 1.2483\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5721 - root_mean_squared_error: 1.2537 - val_loss: 1.5463 - val_root_mean_squared_error: 1.2435\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1283 - root_mean_squared_error: 1.0622\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5419 - root_mean_squared_error: 1.2400 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 269ms/step - loss: 34.6669 - root_mean_squared_error: 5.8879\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.0867 - root_mean_squared_error: 4.6553 - val_loss: 4.0873 - val_root_mean_squared_error: 2.0217\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.4984 - root_mean_squared_error: 2.1209\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1153 - root_mean_squared_error: 1.7613 - val_loss: 2.1874 - val_root_mean_squared_error: 1.4790\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8263 - root_mean_squared_error: 1.3514\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8842 - root_mean_squared_error: 1.3721 - val_loss: 1.8454 - val_root_mean_squared_error: 1.3585\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4925 - root_mean_squared_error: 1.2217\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8035 - root_mean_squared_error: 1.3419 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 310ms/step - loss: 37.9726 - root_mean_squared_error: 6.1622\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 37.7090 - root_mean_squared_error: 6.1407 - val_loss: 37.4746 - val_root_mean_squared_error: 6.1217\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 34.7954 - root_mean_squared_error: 5.8988\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.6412 - root_mean_squared_error: 6.0530 - val_loss: 36.9048 - val_root_mean_squared_error: 6.0749\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 36.0708 - root_mean_squared_error: 6.0059\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.3692 - root_mean_squared_error: 6.0307 - val_loss: 36.3443 - val_root_mean_squared_error: 6.0286\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 36.7249 - root_mean_squared_error: 6.0601\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 36.2374 - root_mean_squared_error: 6.0197 \n",
      "\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.66s/trial, best loss: 1.2434873580932617]\n",
      "Best parameters: {'lr': np.float64(0.0038021185819147895), 'momentum': np.float64(0.04118533146021086)}\n",
      "Best eval rmse: 1.2434873580932617\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment('/wine-quality')\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparamter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,          #  (Tree-structured Parzen Estimator) pour essayer d'améliorer chaque essai (lr et momentum) en fonction des précédents.\n",
    "        max_evals=4,               # Hyperopt va tester 4 combinaisons différentes d'hyperparamètres (lr et momentum)\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x['loss'])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric('eval_rmse', best_run['loss'])\n",
    "    mlflow.tensorflow.log_model(best_run['model'], 'model', signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f'Best parameters: {best}')\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/18 12:24:54 INFO mlflow.models.python_api: It is highly recommended to use `uv` as the environment manager for predicting with MLflow models as its performance is significantly better than other environment managers. Run `pip install uv` to install uv. See https://docs.astral.sh/uv/getting-started/installation for other installation methods.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 1030.51it/s]\n",
      "2025/03/18 12:24:54 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "{\"predictions\": [[4.479798316955566], [6.618078231811523], [6.442264556884766], [4.634179592132568], [4.935753345489502], [7.184676647186279], [5.5371270179748535], [5.8611650466918945], [6.590724945068359], [6.238991737365723], [7.162424564361572], [4.432512283325195], [6.945852756500244], [4.436302661895752], [6.385372161865234], [4.773663520812988], [7.149472236633301], [6.696700572967529], [6.256653785705566], [4.8512043952941895], [4.8480119705200195], [6.290306568145752], [3.9851937294006348], [4.543614864349365], [4.412691593170166], [4.271538257598877], [4.040979385375977], [5.473069667816162], [5.743854999542236], [4.180917263031006], [5.323483943939209], [4.8478827476501465], [6.494192600250244], [4.590468406677246], [5.444142818450928], [6.346088886260986], [7.522966384887695], [4.624701499938965], [4.6655378341674805], [6.389747142791748], [5.342738628387451], [5.682969570159912], [5.3607401847839355], [6.447930335998535], [4.411527633666992], [5.7034478187561035], [5.625709056854248], [5.578429698944092], [4.750258922576904], [6.5374932289123535], [5.059841156005859], [7.409140110015869], [5.592585563659668], [5.292095184326172], [5.9815802574157715], [5.990699768066406], [6.312842845916748], [5.763989448547363], [5.604496479034424], [6.054421901702881], [4.644830226898193], [7.139554977416992], [4.606451988220215], [6.794656753540039], [5.211490154266357], [6.088045120239258], [6.841958522796631], [6.716307640075684], [5.302706241607666], [4.357738018035889], [4.538388729095459], [4.738083839416504], [5.55376672744751], [5.073619842529297], [5.0994038581848145], [5.471729278564453], [5.774057865142822], [5.373818874359131], [8.273046493530273], [5.688656330108643], [5.121484756469727], [4.952546119689941], [4.551336288452148], [4.252312660217285], [6.266254901885986], [5.631956577301025], [4.388108730316162], [5.182923316955566], [6.595990180969238], [5.808988571166992], [6.44891881942749], [6.264797210693359], [4.775737285614014], [7.330941677093506], [5.688744068145752], [6.459235668182373], [5.995819091796875], [4.9788689613342285], [4.9809417724609375], [7.190467357635498], [4.444668769836426], [6.793407917022705], [5.4341816902160645], [5.082306861877441], [6.2458930015563965], [5.000123977661133], [6.054421901702881], [5.340168476104736], [6.696700572967529], [5.5126166343688965], [5.783877372741699], [7.0832390785217285], [6.898217678070068], [5.886826038360596], [4.958420276641846], [6.847849369049072], [6.610371112823486], [7.221461772918701], [5.225335121154785], [6.396839141845703], [5.209576606750488], [6.618099212646484], [6.109397888183594], [4.339681625366211], [4.9918060302734375], [5.913907051086426], [7.4096999168396], [4.749622821807861], [6.297961711883545], [5.4773759841918945], [6.511699199676514], [5.616986274719238], [5.576676368713379], [6.072177886962891], [4.435142517089844], [6.1070733070373535], [3.8579354286193848], [4.778503894805908], [6.8110880851745605], [4.25980806350708], [7.02476167678833], [5.986988544464111], [5.733785152435303], [4.792590618133545], [3.90562105178833], [5.7085185050964355], [3.794320583343506], [4.391479015350342], [5.955479145050049], [4.080288887023926], [6.636346817016602], [5.907230854034424], [7.005662441253662], [6.139954090118408], [5.60829496383667], [5.343644142150879], [7.05856466293335], [6.903751850128174], [5.177770614624023], [8.185428619384766], [6.400017261505127], [4.5353617668151855], [5.573937892913818], [6.91457986831665], [4.480486869812012], [5.271108627319336], [5.101779937744141], [5.978302478790283], [6.641119956970215], [5.613855838775635], [4.243684768676758], [5.909182071685791], [6.68240213394165], [5.041189670562744], [6.843923091888428], [4.921947002410889], [6.616025447845459], [4.466466903686523], [5.6006035804748535], [4.519168853759766], [6.633697986602783], [5.975195407867432], [4.5818400382995605], [5.633443832397461], [4.741466522216797], [4.030788898468018], [5.164271831512451], [4.161050319671631], [6.147100448608398], [8.141047477722168], [5.322311878204346], [4.855494022369385], [5.018988132476807], [7.195680141448975], [5.200140476226807], [6.050243854522705], [6.156760215759277], [6.476500511169434], [4.735429763793945], [5.79557991027832], [4.488792896270752], [5.309082508087158], [7.149672985076904], [5.0153117179870605], [5.113640785217285], [4.594984531402588], [8.413198471069336], [5.238931655883789], [6.160898208618164], [6.232734203338623], [5.905428409576416], [7.157425403594971], [5.622997760772705], [5.842104434967041], [4.849692344665527], [7.019548416137695], [4.864249229431152], [7.58498477935791], [7.139554977416992], [6.507397174835205], [5.735198974609375], [5.892247200012207], [4.221215724945068], [6.150177478790283], [7.003669738769531], [4.339990139007568], [5.747600078582764], [7.714065074920654], [6.403012752532959], [5.617410659790039], [3.95516300201416], [4.583745002746582], [5.182069778442383], [4.484430313110352], [5.1841301918029785], [8.49032974243164], [5.66874885559082], [5.697512149810791], [4.514871597290039], [4.653592109680176], [5.077592372894287], [6.615839958190918], [7.235092639923096], [5.981313228607178], [7.298497200012207], [4.789268493652344], [7.543599605560303], [4.3723015785217285], [5.302735328674316], [3.793459415435791], [5.462642192840576], [6.427162170410156], [4.620675563812256], [5.146641254425049], [5.049101829528809], [4.466703414916992], [4.917063236236572], [6.4938788414001465], [5.215357303619385], [5.700709819793701], [4.9409027099609375], [5.69219446182251], [4.958284854888916], [4.827584743499756], [6.460856914520264], [6.080195903778076], [5.225101947784424], [5.1752238273620605], [5.897612571716309], [4.967138767242432], [7.993053913116455], [5.585678577423096], [6.167644023895264], [6.42780065536499], [5.001773834228516], [5.04961633682251], [6.980740070343018], [5.655234336853027], [5.567051887512207], [7.2881388664245605], [5.385833263397217], [5.0994038581848145], [6.744614124298096], [5.411955833435059], [5.842635631561279], [6.258584499359131], [7.76173210144043], [5.001948833465576], [5.309619426727295], [3.7631845474243164], [6.278413772583008], [5.4472150802612305], [5.975545883178711], [5.298059940338135], [6.339134693145752], [5.720333576202393], [6.232795238494873], [5.531547546386719], [6.398650646209717], [4.528397083282471], [5.059841156005859], [5.36610746383667], [11.47661304473877], [5.020208835601807], [7.5239667892456055], [4.400398254394531], [6.189139366149902], [4.729044437408447], [7.412590026855469], [6.092504501342773], [4.479639530181885], [6.1097564697265625], [4.824039936065674], [6.0481181144714355], [6.608521938323975], [7.438963413238525], [5.266339302062988], [6.411864757537842], [5.068081378936768], [5.533404350280762], [4.408349990844727], [5.337047576904297], [6.677397727966309], [6.345676422119141], [6.1317219734191895], [4.418417453765869], [5.967070579528809], [5.654776096343994], [9.163456916809082], [6.140767574310303], [4.029791831970215], [7.316453456878662], [7.271379470825195], [5.8769850730896], [6.006138324737549], [6.680338382720947], [6.9590229988098145], [5.992927551269531], [5.242088794708252], [5.011520862579346], [6.025486469268799], [4.982239723205566], [4.7523980140686035], [7.761863708496094], [5.142208099365234], [5.116422653198242], [7.694140911102295], [5.454579830169678], [6.454127788543701], [5.200403690338135], [7.17115592956543], [5.888405799865723], [6.2458930015563965], [4.612401008605957], [6.666057586669922], [5.146641254425049], [5.384551525115967], [5.70811653137207], [8.082565307617188], [6.651549339294434], [4.8945441246032715], [4.888976097106934], [4.486611366271973], [4.882331848144531], [5.396590709686279], [5.422550201416016], [6.036801815032959], [4.735036373138428], [4.475883483886719], [5.902896881103516], [4.707818508148193], [5.040249824523926], [4.427014350891113], [6.494342803955078], [6.867570877075195], [5.086104869842529], [7.524731636047363], [5.225161075592041], [5.604557037353516], [5.591526031494141], [6.197208881378174], [5.063678741455078], [6.824642658233643], [6.46128511428833], [4.105443954467773], [6.325109004974365], [5.565852642059326], [4.271312236785889], [5.616719722747803], [5.840540409088135], [4.53012752532959], [6.376928329467773], [5.285545825958252], [5.329883575439453], [5.257819652557373], [6.496209144592285], [5.6248579025268555], [4.45092248916626], [6.355180740356445], [4.524898529052734], [6.14807653427124], [6.657310962677002], [4.977468013763428], [6.26950216293335], [4.921189785003662], [5.750964641571045], [7.1520466804504395], [4.538386821746826], [6.278507709503174], [5.6386399269104], [5.298059940338135], [4.786632061004639], [6.310608386993408], [4.442193984985352], [5.236847400665283], [4.232544422149658], [5.627537250518799], [5.076535701751709], [5.789320468902588], [5.975857734680176], [6.12578821182251], [5.05291223526001], [5.688069820404053], [5.982555389404297], [6.9710564613342285], [5.766615390777588], [5.391839504241943], [6.787932395935059], [5.597021579742432], [5.307178497314453], [5.832376003265381], [4.4614644050598145], [4.3562846183776855], [6.881123065948486], [5.988311290740967], [5.115707874298096], [5.086919784545898], [7.433899402618408], [4.200462818145752], [7.669748306274414], [6.524593830108643], [8.971170425415039], [5.471729278564453], [4.9649858474731445], [5.465111255645752], [6.551429271697998], [5.827127933502197], [5.4050164222717285], [4.560108661651611], [6.459893703460693], [3.2833056449890137], [4.937634468078613], [6.520637512207031], [6.933145046234131], [6.445031642913818], [5.7331366539001465], [6.923680782318115], [7.05867338180542], [4.382807731628418], [5.836045742034912], [5.773094177246094], [7.128864765167236], [5.735436916351318], [5.591284275054932], [6.690385341644287], [6.873657703399658], [5.9417524337768555], [6.193339824676514], [7.399979114532471], [6.2997355461120605], [4.470993995666504], [7.915143013000488], [6.477759838104248], [4.239739418029785], [4.961319446563721], [5.895138740539551], [5.421546459197998], [4.301136493682861], [6.240736484527588], [6.451200008392334], [4.917306423187256], [5.221927165985107], [4.649055004119873], [5.323338031768799], [4.840907096862793], [5.882957935333252], [4.95167350769043], [6.015193939208984], [5.6739397048950195], [8.07425308227539], [6.3420729637146], [4.069362163543701], [6.248654842376709], [5.606358051300049], [6.816817760467529], [6.6158766746521], [5.294000148773193], [4.466703414916992], [6.488057613372803], [4.682102680206299], [6.419708728790283], [3.7817063331604004], [5.886422157287598], [6.439907073974609], [4.140805721282959], [5.973065376281738], [5.970526218414307], [6.980575084686279], [5.563720703125], [6.580976963043213], [6.36964750289917], [4.796236038208008], [4.166341304779053], [6.509938716888428], [5.02821159362793], [5.438870906829834], [4.86900520324707], [5.237198829650879], [3.7540297508239746], [5.150801658630371], [4.767256736755371], [4.930438041687012], [5.6563286781311035], [5.812490940093994], [4.915975570678711], [4.8478827476501465], [5.497219562530518], [4.604118347167969], [4.002727031707764], [18.6253719329834], [5.739517688751221], [5.839357376098633], [4.388108730316162], [5.829369068145752], [5.067915439605713], [5.889219760894775], [6.328866958618164], [8.569735527038574], [7.057778835296631], [6.725942134857178], [4.702815532684326], [4.210806846618652], [5.692389011383057], [5.545101642608643], [5.862742900848389], [4.95973014831543], [6.608400344848633], [6.270930767059326], [4.944366931915283], [4.634768009185791], [4.802529811859131], [6.2450175285339355], [5.72634220123291], [4.156900405883789], [6.843923091888428], [6.597033500671387], [6.048797607421875], [7.712522983551025], [3.6556882858276367], [5.885056972503662], [6.467661380767822], [5.318724155426025], [6.334137439727783], [5.543087482452393], [5.8823161125183105], [5.911478519439697], [5.949297904968262], [5.345259189605713], [6.646610260009766], [4.815910816192627], [5.396331310272217], [6.389016628265381], [5.711989879608154], [5.065263271331787], [4.616832256317139], [5.941098690032959], [5.818436145782471], [5.563720703125], [6.946148872375488], [6.543975353240967], [5.294506549835205], [7.404670238494873], [7.462965488433838], [5.117356777191162], [5.304778099060059], [4.543083190917969], [6.141284465789795], [4.615438938140869], [5.599617958068848], [5.598476409912109], [5.604557037353516], [5.961667060852051], [4.935135841369629], [7.733273983001709], [6.408474445343018], [5.971358776092529], [6.208338737487793], [5.611595630645752], [5.328701496124268], [5.077208042144775], [4.750258922576904], [6.533769130706787], [5.776364803314209], [8.122367858886719], [6.359614372253418], [7.994368076324463], [5.176361560821533], [6.976531028747559], [6.494342803955078], [5.444377422332764], [6.0002970695495605], [7.851566314697266], [5.459226608276367], [4.840968608856201], [5.788383960723877], [6.72472620010376], [5.334743499755859], [5.803646087646484], [5.068611145019531], [5.214279651641846], [5.743854999542236], [6.567690372467041], [5.540718078613281], [5.430189609527588], [6.561513423919678], [5.289308547973633], [5.337047576904297], [6.201613903045654], [6.777733325958252], [5.690631866455078], [3.2142586708068848], [5.682969570159912], [5.8296122550964355], [4.770266532897949], [4.778201103210449], [5.67065954208374], [6.26570987701416], [5.336739540100098], [6.159514427185059], [4.49272346496582], [4.68688440322876], [7.277148723602295], [5.9485297203063965], [4.950651168823242], [5.216175079345703], [4.183572292327881], [4.396873950958252], [5.653748035430908], [6.897388935089111], [4.956973075866699], [7.56814432144165], [5.1827874183654785], [4.7898993492126465], [5.900606632232666], [6.597033500671387], [4.634768009185791], [4.563436031341553], [3.8945302963256836], [4.958711624145508], [6.31538200378418], [8.1762056350708], [6.2915568351745605], [7.976747989654541], [4.543614864349365], [5.602395534515381], [6.5542168617248535], [6.227921009063721], [4.633597373962402], [6.992014408111572], [4.872982501983643], [6.958986282348633], [6.325979709625244], [5.384101390838623], [6.3532395362854], [6.879086494445801], [6.81056547164917], [4.694721698760986], [7.733273983001709], [5.615961074829102], [6.418318748474121], [5.798348426818848], [4.980724811553955], [5.709856986999512], [6.6136956214904785], [5.997308254241943], [4.834757328033447], [6.010470867156982], [5.636499881744385], [6.464932441711426], [4.334747314453125], [5.327563285827637], [5.737730503082275], [6.5374932289123535], [7.171456813812256], [8.499046325683594], [8.1762056350708], [3.8083629608154297], [5.308759689331055], [7.156851291656494], [6.440433979034424], [4.653078079223633], [4.605018615722656], [3.9775943756103516], [7.070063591003418], [4.934304237365723], [5.114040851593018], [6.719793796539307], [5.532805442810059], [4.091057300567627], [5.070174694061279], [5.086148738861084], [7.32844352722168], [6.474992275238037], [6.832177639007568], [5.387044429779053], [5.234616756439209], [5.462636470794678], [6.108774662017822], [6.63064432144165], [5.406854152679443], [3.2530112266540527], [6.938234806060791], [5.618960857391357], [6.410132884979248], [5.8889570236206055], [4.435545921325684], [3.855771064758301], [5.604592323303223], [5.84986686706543], [4.335483074188232], [4.390695571899414], [4.594984531402588], [7.753219127655029], [7.075864315032959], [4.326527118682861], [4.993935585021973], [7.170578479766846], [4.2426438331604], [7.126603126525879], [5.348372936248779], [6.3386735916137695], [6.160637378692627], [5.6540656089782715], [5.520142078399658], [7.010514736175537], [3.9349865913391113], [5.621690273284912], [4.034119129180908], [5.346147537231445], [5.739595890045166], [5.316097259521484], [4.2497053146362305], [4.80392599105835], [7.906952857971191], [4.970168590545654], [5.097835063934326], [6.139954090118408], [5.131076812744141], [4.753490924835205], [5.8029303550720215], [7.5964741706848145], [5.044924736022949], [5.7453837394714355], [5.3415303230285645], [5.477283000946045], [6.580269813537598], [4.849734306335449], [6.513721942901611], [6.051459789276123], [5.453164100646973], [4.965341091156006], [7.436879634857178], [5.305998802185059], [4.979702949523926], [5.23708438873291], [6.467661380767822], [6.309186935424805], [6.602405071258545], [7.530520439147949], [6.108545303344727], [5.024453639984131], [5.767055511474609], [6.222425937652588], [4.576642036437988], [6.02100133895874], [4.846098899841309], [6.557476997375488], [4.800034046173096], [4.325567722320557], [6.381332874298096], [5.311352252960205], [5.03486967086792], [4.764737606048584], [4.129796504974365], [5.226953983306885], [7.627063274383545], [7.705574989318848], [5.041250705718994], [5.825512886047363], [5.653656482696533], [4.817984104156494], [4.821206569671631], [3.8719687461853027], [5.8539299964904785], [5.311166763305664], [4.975693225860596], [6.35467004776001], [5.148168563842773], [7.0210957527160645], [6.255218029022217], [5.608138561248779], [4.7507243156433105], [4.683839321136475], [5.542541027069092], [6.1960673332214355], [5.769737720489502], [6.28419828414917], [5.197151184082031], [6.144369125366211], [8.154109001159668], [6.198145389556885], [6.768106937408447], [6.614548206329346], [4.6480913162231445], [4.951822757720947], [4.683839321136475], [7.477687358856201], [4.860136032104492], [4.963550090789795], [6.773248195648193], [3.905620574951172], [5.638990879058838], [5.151949405670166], [7.1520466804504395], [6.635215759277344], [4.525264739990234], [4.5824360847473145], [5.726097583770752], [4.546151161193848], [6.323764801025391], [6.807338237762451], [4.674694538116455], [4.743239402770996], [5.574824810028076], [5.292742729187012], [5.63176965713501], [3.962618350982666], [6.806906223297119], [4.476836681365967], [5.487227916717529], [5.643019199371338], [4.495244979858398], [6.4548115730285645], [9.292901992797852], [5.932727336883545], [7.1854729652404785], [5.349923610687256], [5.030542850494385], [5.720457553863525], [5.653672695159912], [5.7809157371521], [5.305998802185059], [4.059398174285889], [6.63322639465332], [5.645437717437744], [7.045345306396484], [5.948690891265869], [5.00478458404541], [6.542585849761963], [5.46873140335083], [6.10485315322876], [4.8719892501831055], [6.874246120452881], [5.148168563842773], [4.173707962036133], [7.37162446975708], [6.888024806976318], [5.1100897789001465], [7.750667095184326], [4.9794416427612305], [5.1430487632751465], [4.1158447265625], [7.973765850067139], [5.576724052429199], [4.955334663391113], [5.730001926422119], [5.5522541999816895], [4.589865207672119], [5.408255577087402], [4.421083927154541], [5.371100902557373], [6.721467971801758], [6.110257148742676], [6.68875789642334], [5.438870429992676], [8.113896369934082], [5.793910026550293], [5.347278118133545], [6.195253372192383], [5.476503849029541], [4.912055492401123], [6.602405071258545], [4.873672008514404], [4.709179878234863], [5.400058269500732], [5.79557991027832], [5.966063976287842], [6.488209247589111], [5.863161563873291], [5.086104869842529], [6.437950134277344], [6.011418342590332], [5.416173458099365], [5.410640716552734], [5.491352558135986], [5.803646087646484], [5.789666652679443], [5.848667621612549], [4.857261657714844], [6.866326808929443], [4.867861270904541], [6.169483661651611], [6.557018756866455], [8.45845890045166], [7.489554405212402], [6.225886821746826], [8.487807273864746], [6.0617356300354], [4.735429763793945], [5.266600608825684], [6.554029941558838], [6.053141117095947], [5.019789218902588], [6.464759826660156], [5.433290481567383], [6.63541841506958], [4.619394779205322], [5.23708438873291], [6.542585849761963], [5.003438949584961], [5.549795150756836], [7.082080364227295], [5.9974684715271], [4.094616413116455], [7.180509090423584], [3.8620920181274414], [4.938556671142578], [5.837912082672119], [4.310913562774658], [4.493173599243164], [3.873284339904785], [4.85966682434082], [4.567188739776611], [6.05039119720459], [5.362173557281494], [6.202577114105225], [6.834699630737305], [5.565175533294678], [3.5921759605407715], [5.3653950691223145], [7.941201686859131], [5.215836048126221], [5.960151195526123], [6.476038932800293], [6.214585781097412], [5.381195068359375], [5.929052829742432], [6.824642658233643], [4.712331771850586], [9.725235939025879], [6.572787761688232], [4.170410633087158], [6.0472493171691895], [3.9510531425476074], [4.694206714630127], [6.326594829559326], [4.869356155395508], [5.203249454498291], [4.03165864944458], [5.966859340667725], [5.607101917266846], [5.0740966796875], [4.600757122039795], [5.2313103675842285], [5.722327709197998], [4.877988338470459], [3.6256237030029297], [5.272749423980713], [5.803646087646484], [4.223544597625732], [6.342458248138428], [4.360507488250732], [5.035040378570557], [4.674905776977539], [6.463348865509033], [6.494342803955078], [6.289498329162598], [6.2458930015563965], [5.158507347106934], [6.336675643920898], [5.329185485839844], [3.7398581504821777], [6.742920398712158], [4.1591997146606445], [4.869356155395508], [5.538360595703125], [5.655806064605713], [5.796245574951172], [5.8369269371032715], [7.226107120513916], [4.769772529602051], [5.887639999389648], [5.961642742156982], [4.989115238189697], [5.0098700523376465], [8.054323196411133], [4.193790435791016], [6.708297252655029], [6.3386735916137695], [6.43859338760376], [6.054421901702881], [6.200364112854004], [7.04070520401001], [5.4137372970581055], [5.547489166259766], [5.016383171081543], [6.001354694366455], [5.738719463348389], [5.646133899688721], [5.553826332092285], [3.919053554534912], [4.769772529602051], [5.2378950119018555], [6.512998104095459], [4.594984531402588], [7.084944248199463], [5.125720500946045], [4.891988754272461], [5.168820858001709], [5.043371677398682], [6.110053539276123], [6.948080062866211], [4.649055004119873], [4.170798301696777], [5.150655269622803], [4.5027384757995605], [7.0832390785217285], [5.230306625366211], [6.839000225067139], [5.680100917816162], [5.731257438659668], [4.8793158531188965], [4.551472187042236], [4.965190410614014], [5.187028408050537], [5.304966926574707], [3.8659963607788086], [4.619876861572266], [5.335643291473389], [4.836999416351318], [5.553969383239746], [4.091853618621826], [4.924100399017334], [6.54892110824585], [4.707641124725342], [6.019751071929932], [3.7237462997436523], [5.913882732391357], [6.554029941558838], [4.530686378479004], [8.057541847229004], [5.329006195068359], [4.773899555206299], [5.352544784545898], [6.43694543838501], [6.878884315490723], [5.589996814727783], [6.216550827026367], [6.256942272186279], [7.222358703613281], [6.325626373291016], [7.130537033081055], [4.67977237701416], [5.993937015533447], [6.258584499359131], [4.384096622467041], [6.467661380767822], [6.722854137420654], [5.653570652008057], [5.305500507354736], [4.536534309387207], [5.555776119232178], [5.423404216766357], [5.667656421661377], [4.747870922088623], [4.70721960067749], [5.488322734832764], [5.5538811683654785], [5.352468013763428], [5.737730503082275], [6.900511741638184], [6.664876461029053], [4.7524824142456055], [7.0430073738098145], [5.162126064300537], [5.803646087646484], [5.020251750946045], [6.4510908126831055], [5.068982124328613], [4.434873580932617], [5.5191121101379395], [4.343674182891846], [6.839621543884277], [5.152679443359375], [4.452541351318359], [5.485091686248779], [7.721568584442139], [5.045976161956787], [6.020155429840088], [5.3653950691223145], [5.912675380706787], [7.521653652191162], [5.023482322692871], [6.477330684661865], [5.48707389831543], [5.337047576904297], [4.060919284820557], [5.341048240661621], [6.6744065284729], [6.520805358886719], [5.764702796936035], [5.909182071685791], [6.318305492401123], [5.933248996734619], [6.550454139709473], [4.778503894805908], [4.883646488189697], [4.204533576965332], [6.7098517417907715], [7.307309627532959], [5.514855861663818], [5.578914165496826], [6.052155017852783], [5.602095127105713], [4.872414588928223], [5.939364433288574], [4.772313594818115], [3.8328943252563477], [5.941262722015381], [4.437539100646973], [8.826101303100586], [5.2833967208862305], [7.353262901306152], [5.517795085906982], [5.611631870269775], [6.335575580596924], [5.604557037353516], [5.221391201019287], [5.249788761138916], [4.984808444976807], [5.08596658706665], [5.908766746520996], [6.1704630851745605], [4.539306640625], [6.476810455322266], [5.5862956047058105], [7.267262935638428], [5.963771343231201], [5.6386399269104], [8.020381927490234], [7.254954814910889], [6.678018093109131], [6.27653169631958], [4.496740341186523], [7.636891841888428], [5.183148384094238], [4.090009689331055], [6.713009357452393], [4.605011940002441], [5.604557037353516], [4.223544597625732], [6.425705909729004], [5.238838195800781], [4.9410295486450195], [8.341093063354492], [6.8170294761657715], [6.298701763153076], [5.0060133934021], [5.325986385345459], [6.197533130645752], [5.121100902557373], [5.148207187652588], [5.2556681632995605], [4.361051559448242], [5.643019199371338], [5.215758323669434], [7.228531360626221], [5.607112407684326], [4.697004795074463], [6.4977216720581055], [5.819092750549316], [5.796372413635254], [5.349316120147705], [4.425786018371582], [4.35213041305542], [7.342275142669678], [6.197756290435791], [6.751936912536621], [6.645899295806885], [5.378536701202393], [6.279965877532959], [6.371672630310059], [4.022182941436768], [5.949297904968262], [5.160887718200684], [5.213218688964844], [6.282003879547119], [6.937946796417236], [5.105219841003418], [5.086806774139404], [7.521146297454834], [6.518996715545654], [6.926212787628174], [6.375010967254639], [4.950135707855225]]}"
     ]
    }
   ],
   "source": [
    "## Inferencing\n",
    "\n",
    "model_uri = 'runs:/f65dbf360b1a4a73ae7730f164ba2096/model'\n",
    "\n",
    "# Replace INPUT_EXAMPLE with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "input_data = X_test\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"local\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.4797983],\n",
       "       [6.618078 ],\n",
       "       [6.4422646],\n",
       "       ...,\n",
       "       [6.926213 ],\n",
       "       [6.375011 ],\n",
       "       [4.9501357]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model as a PyFuncModel.\n",
    "model_uri = 'runs:/f65dbf360b1a4a73ae7730f164ba2096/model'\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'wine-quality'.\n",
      "Created version '1' of model 'wine-quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1742297853255, current_stage='None', description=None, last_updated_timestamp=1742297853255, name='wine-quality', run_id='f65dbf360b1a4a73ae7730f164ba2096', run_link=None, source='file:///c:/Users/nico_/Desktop/MLOPS/MLFlowStarter/DLMLFLOW/mlruns/110240270250196691/f65dbf360b1a4a73ae7730f164ba2096/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## register in the model registry    (Enregistre le model dans le registre MLFLOW)\n",
    "mlflow.register_model(model_uri, \"wine-quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
